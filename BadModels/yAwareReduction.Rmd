---
title: "yAwareProcess"
author: "Win-Vector LLC"
date: "November 10, 2015"
output: html_document
---

Example of bad variable starving out good ones.


```{r}
# devtools::install_github('WinVector/WVPlots')
library('WVPlots')

# make an example data set with some signal variables and some noise variables
mkData <- function(rows,nSignalFeatures,nNoiseFeatures) {
  yName = 'y'
  yValues <- factor(c(FALSE,TRUE))
  yData = sample(yValues,replace=TRUE,size=rows)
  d <- data.frame(y=yData,stringsAsFactors=FALSE)
  if(nSignalFeatures>0) {
    mkVar <- function(v) {
      (as.numeric(yData)-0.5)*rbinom(rows,1,0.1)
    }
    varNames <- paste('x',seq_len(nSignalFeatures),sep='_')
    varValues <- data.frame(lapply(varNames,mkVar),
                            stringsAsFactors = FALSE)
    colnames(varValues) <- varNames
    d <- cbind(d,varValues)
  }
   if(nNoiseFeatures>0) {
    mkVar <- function(v) {
      rnorm(rows,mean=0)
    }
    varNames <- paste('n',seq_len(nNoiseFeatures),sep='_')
    varValues <- data.frame(lapply(varNames,mkVar),
                            stringsAsFactors = FALSE)
    colnames(varValues) <- varNames
    d <- cbind(d,varValues)
  }
  list(d=d,
       varNames=setdiff(colnames(d),yName),
       yValues=yValues,
       yName=yName)
}

runExample <- function(rows,nSignalFeatures,nNoiseFeatures,trainer,predictor,title) {
  print('********************')
  print(title)
  print(sys.call(0)) # print call and arguments
  defs <- mkData(rows,nSignalFeatures,nNoiseFeatures)
  dTrain <- defs$d
  yValues <- defs$yValues
  varNames <- defs$varNames
  dTest <- mkData(rows,nSignalFeatures,nNoiseFeatures)$d
  model <- trainer(yName='y',varNames=varNames,yValues=yValues,
                   data=dTrain)
  dTrain$predScore <- predictor(model,newdata=dTrain,yValues=yValues)
  scoreThreshold <- median(dTrain$predScore)
  dTrain$pred <- ifelse(dTrain$predScore>=scoreThreshold,
                        as.character(yValues[[2]]),
                        as.character(yValues[[1]]))
  tabTrain <- table(truth=dTrain$y,
                    predict=dTrain$pred)
  print('train set results')
  print(tabTrain)
  if(length(unique(dTrain$pred))>1) {
     print(fisher.test(tabTrain))
  }
  print(ROCPlot(dTrain,'predScore','y',title=paste('Train',title,'ROC plot')))
  dTest$predScore <- predictor(model,newdata=dTest,yValues=yValues)
  dTest$pred <- ifelse(dTest$predScore>=scoreThreshold,
                       as.character(yValues[[2]]),
                       as.character(yValues[[1]]))
  tabTest <- table(truth=dTest$y,
                   predict=dTest$pred)
  print('hold-out test set results')
  print(tabTest)
  if(length(unique(dTest$pred))>1) {
     print(fisher.test(tabTest))
  }
  print(ROCPlot(dTest,'predScore','y',title=paste('Test',title,'ROC plot')))
  print('********************')
  list(tabTrain=tabTrain,tabTest=tabTest)
}
```


```{r}
# glm example
set.seed(123525)   # make result more repeatable
res <- runExample(rows=800,nSignalFeatures=20,nNoiseFeatures=400,title='GLM',
                  trainer=function(yName,varNames,yValues,data) {
                    formula <- as.formula(paste(yName,paste(varNames,collapse=' + '),
                                                sep=' ~ '))
                    glm(formula,data,family=binomial(link='logit')) 
                  },
                  predictor=function(model,newdata,yValues) { 
                    predict(model,newdata=newdata,type='response')
                  }
)
```



```{r}
# glm principeal components example
set.seed(123525)   # make result more repeatable
res <- runExample(rows=800,nSignalFeatures=20,nNoiseFeatures=400,title='GLM principal components',
                  trainer=function(yName,varNames,yValues,data) {
                    pr <- prcomp(as.matrix(data[,varNames]),center=TRUE,scale=TRUE)
                    maxComp <- min(100,length(varNames))
                    smallCoefs <- which(pr$sdev<=1.0e-3)
                    if(length(smallCoefs)>0) {
                      maxComp <- min(maxComp,smallCoefs[[1]])
                    }
                    xform <- pr$rotation[,1:maxComp]
                    dataT <- data.frame(as.matrix(data[,varNames]) %*% xform)
                    dataT[[yName]] <- data[[yName]]
                    formula <- as.formula(paste(yName,paste(colnames(xform),collapse=' + '),
                                                sep=' ~ '))
                    model <- glm(formula,dataT,family=binomial(link='logit'))
                    list(varNames=varNames,xform=xform,model=model)
                  },
                  predictor=function(model,newdata,yValues) { 
                    newdataT <- data.frame(as.matrix(newdata[,model$varNames]) %*% model$xform)
                    predict(model$model,newdata=newdataT,type='response')
                  }
)
```




```{r}
# glm variable selection example
set.seed(123525)   # make result more repeatable
res <- runExample(rows=800,nSignalFeatures=20,nNoiseFeatures=400,title='GLM with variable selection',
                  trainer=function(yName,varNames,yValues,data) {
                    treatment <- vtreat::designTreatmentsC(data,varNames,yName,TRUE,
                                                           verbose=FALSE)
                    pruneSig = 0.05
                    dataT <- vtreat::prepare(treatment,data,pruneSig=pruneSig)
                    selvars <- setdiff(colnames(dataT),yName)
                    formula <- as.formula(paste(yName,paste(selvars,collapse=' + '),
                                                sep=' ~ '))
                    model = glm(formula,dataT,family=binomial(link='logit'))
                    list(treatment=treatment,pruneSig=pruneSig,model=model)
                  },
                  predictor=function(model,newdata,yValues) { 
                    newdataT <- vtreat::prepare(model$treatment,newdata,pruneSig=model$pruneSig)
                    predict(model$model,newdata=newdataT,type='response')
                  }
)
```


